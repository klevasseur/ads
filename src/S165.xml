<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="s-power-series">
<title>Power Series</title>
<subsection><title>Definition</title>

<p>Earlier in this chapter, we found that a polynomial of degree <m>n</m> over a ring <m>R</m>  is an expression of the form
\[f(x)=\sum_{i=0}^n a_i x^i=a_0 + a_1 x+a_2 x^2+ \cdots +a_n x^n\]  
where  \(n\geq 0\), each of the \(a_i\) are elements of <m>R</m> and \(a_n\neq 0\). In Section 8.5 we defined a generating function of a sequence <m>s</m>
with terms \(s_0\), \(s_1\), \(s_2, \ldots\)  as the infinite sum
\[G(s,z)= \sum_{i=0}^{\infty } s_i z^i=s_0 + s_1 z+s_2 z^2+ \cdots\]</p>
<p>The main difference between these two expressions, disregarding notation, is that the latter is an infinite expression and the former is a finite
expression. In this section we will extend the algebra of polynomials to the algebra of infinite expressions like \(G(s, z)\),  which are called power series.</p>
<definition xml:id="def-power-series"><title>Power Series</title>
<idx>Power Series</idx>
<notation><usage>R[[x]]</usage><description>the set of all powers series in \(R\)</description></notation>
<statement><p>Let \([R; +,\cdot ]\) be a ring. A power series over \(R\) is an expression of the form
\[f(x)=\sum_{i=0}^{\infty } a_i x^i=a_0 + a_1 x+a_2 x^2+ \cdots\] 
where \(a_1, a_2, a_3,\ldots \in  R\).  The set of all such expressions is denoted by \(R[[x]]\).</p></statement>
</definition>

 <p>Our first observation in our comparison of \(R[x]\) and \(R[[x]]\) is that every polynomial is a power series and so \(R[x]\subseteq R[[x]]\). This is true because a polynomial \(a_0 + a_1 x+a_2 x^2+ \cdots +a_n x^n\) of degree <m>n</m> in \(R[x]\), can be thought of as an infinite expression
where \(a_i=0\) for \(i > n\).  In addition, we will see that \(R[[x]]\) is a ring with subring \(R[x]\). </p>

<p>\(R[[x]]\) is given a ring structure by defining addition and multiplication on power series as we did in \(R[x]\), with the modification that, since
we are dealing with infinite expressions, the sums and products will remain infinite expressions that we can determine term by term, as was done in with polynomials.</p> 
<definition xml:id="def-power-series-addition"><title>Power Series Addition</title><statement><p>Given power series <me>\begin{array}{c}
f(x)=\sum_{i=0}^{\infty } a_i x^i=a_0 + a_1 x+a_2 x^2+ \cdots\textrm{  and}\\
g(x)=\sum_{i=0}^{\infty } b_i x^i=b_0 + b_1 x+b_2 x^2+ \cdots\\
\end{array}
</me>  
their sum is 
<me>\begin{split}
f(x)+g(x)&amp;=\sum_{i=0}^{\infty }\left(a_i+b_i\right) x^i\\
&amp;=(a_0 +a_1) + (a_1+b_1) x+(a_2+b_2) x^2+(a_3+b_3) x^3+ \cdots \\
\end{split}</me>.</p></statement></definition>



<definition xml:id="def-power-series-multiplication"><title>Power Series Multiplication</title><statement><p>Given power series <me>\begin{array}{c}
f(x)=\sum_{i=0}^{\infty } a_i x^i=a_0 + a_1 x+a_2 x^2+ \cdots\textrm{  and}\\
g(x)=\sum_{i=0}^{\infty } b_i x^i=b_0 + b_1 x+b_2 x^2+ \cdots\\
\end{array}
</me>  
their product is 
<me>\begin{split}
f(x)\cdot g(x)&amp;=\sum_{i=0}^{\infty } d_i x^i \quad \textrm{where }d_i= \sum_{j=0}^i a_j b_{i-j}\\
&amp;=(a_0\cdot b_0) + (a_0\cdot b_1+a_1\cdot b_0) x+(a_0\cdot b_2+a_1\cdot b_1+a_2\cdot b_0) x^2+ \cdots  \\
\end{split}</me>.</p></statement></definition>


<example xml:id="ex-ps-calculations"><title>Some Power Series Calcuations</title>
<p> Let   
<me>\begin{array}{c}
f(x)=\sum_{i=0}^{\infty}  i x^i=0 + 1 x+2 x^2+3x^3+ \cdots \quad \textrm{and}\\
g(x)=\sum_{i=0}^{\infty} 2^i x^i=1 +2 x+4 x^2+8x^3+ \cdots \\
\end{array}</me>
be elements in \(\mathbb{Z}[[x]]\).  Let us compute \(f(x) + g(x)\) and \(f(x)\cdot g(x)\).  First the sum:
<me>\begin{split}
 f(x) + g(x) &amp; =\sum_{i=0}^{\infty } i x^i+\sum_{i=0}^{\infty } 2^i x^i\\
 	&amp;=\sum_{i=0}^{\infty} \left(i+2^i\right) x^i\\
	&amp; =1+3x+6x^2+11x^3+ \cdots\\
\end{split}</me>
The product is a bit more involved:
<me>\begin{split}
 f(x) \cdot g(x) &amp; =\left(\sum_{i=0}^{\infty } i x^i\right)\cdot \left(\sum_{i=0}^{\infty } 2^i x^i\right)\\
 	&amp;=\left(0+ 1 x+2 x^2+3x^3+ \cdots \right)\cdot \left(1 +2 x+4 x^2+8x^3+ \cdots \right)\\
	&amp;=0\cdot 1 + (0\cdot 2 + 1\cdot 1)x + (0\cdot 4+1\cdot 2+2\cdot 1)x^2+ \cdots\\
	&amp;= x + 4 x^2+ 11 x^3 + \cdots\\
	&amp;= \sum_{i=0}^{\infty } d_i x^i\quad\quad\textrm{where } d_i= \sum_{j=0}^i j 2^{i-j}\\
\end{split}</me>
We can compute any value of \(d_i\), with the amount of time/work required increasing as \(i\) increases.</p>
<sage>
<input>
def d(i):
    s=0
    for j in range(1,i+1):
        s+=j*2^(i-j)
    return s
d(20)
</input>
<output>
2097130
</output>
</sage>
<p>A closed-form expression for \(d_i\) would be desirable.  Using techniques from Chapter 8,  the formula is  \(d_i=2^{i+1}-i-2\), which we leave it to the reader to derive.  Hence,
\(f(x)\cdot g(x) =\sum_{i=0}^{\infty } (2^{i+1}-i-2) x^i\)
</p></example> 

</subsection>
<subsection><title>Properties, Units</title>

<p>We have seen that addition and multiplication in \(R[[x]]\) is virtually identical to that in \(R[x]\). The following theorem parallels <xref ref="theorem-polynomial-ring-properties" text="type-global" />, establishing the ring properties of \(R[[x]]\).</p>

<theorem xml:id="theorem-power-series-properties"><title>Properties of Power Series</title><statement><p>Let [R, +, $\cdot $] be a ring. Then:<ol label="(1)">
<li><p>\(R[[x]]\) is a ring under the operations of power series addition and multiplication, which depend on  the operations in R.</p></li>
<li><p>If R is a commutative ring, then \(R[[x]]\) is a commutative ring.</p></li>
<li><p>If R is a ring with unity, \textup{ 1}, then \(R[[x]]\) is a ring with unity (the unity in R[x] is \(1 + 0x + 0 x^2 + \cdots\)).</p></li>
<li><p>If R is an integral domain, then \(R[[x]]\) is an integral domain.</p></li>
<li><p>If F is a field, then \(F[[x]]\) is not a field. However, \(F[[x]]\) is an integral domain.</p></li>
</ol>
</p>
</statement></theorem> 


<p>We are most interested in the situation when the set of coefficients is a field. The theorem above indicates that when \(F\) is a field, \(F[[x]]\) is
an integral domain. A reason that \(F[[x]]\) is not a field is the same as one that we can cite for \(F[x]\), namely that <m>x</m> does not have multiplicative inverse in \(F[[x]]\).</p>

<p>With all of these similarities, one might wonder if the rings of polynomials and power series over a field are isomorphic.  It turns out that they are not. The difference between \(F[x]\) and \(F[[x]]\) become apparent when one studies which elements are units in each. First we prove that the only units in \(F[x]\) are the nonzero constants; that is, the nonzero elements of <m>F</m>.</p>


<theorem xml:id="theorem-polynomial-units"><title>Units of \(F[x]\)</title>
<statement><p>Let \([F; +, \cdot ]\) be a field. Polynomial \(f(x)\) is a unit in \(F[x]\) if and only if it is a nonzero constant polynomial.</p></statement>
<proof>
<case direction="forward">
<p>Let \(f(x)\) be a unit in \(F[x]\). Then \(f(x)\) has a multiplicative inverse, call it \(g(x)\), such that \(f(x) \cdot
 g(x) = 1\). Hence, the \(\deg  (f(x)\cdot  g(x)) = \deg  (1) = 0\). But \(\deg  (f(x)\cdot  g(x)) = \deg  f(x) + \deg  g(x)\). So \(\deg  f(x) +
\deg  g(x) = 0\), and since the degree of a polynomial is always nonnegative, this can only happen when the \(\deg  f(x) = \deg  g(x) = 0\). Hence,
\(f(x)\) is a constant, an element of <m>F</m>, which is a unit if and only if it is nonzero.</p></case>
<case direction="backward">
<p>If \(f(x)\) is a nonzero element of <m>F</m>, then it is a unit since <m>F</m> is a field.  Thus it has an inverse, which
is also in \(F[x]\) and so \(f(x)\) is a unit of \(F[x]\).</p></case>
</proof>
</theorem> 



<p>Before we proceed to categorize the units in \(F[[x]]\), we remind the reader that two power series \(a_0 + a_1 x+a_2 x^2+ \cdots\) and \(b_0 + b_1
x+b_2 x^2+ \cdots\) are equal if and only if corresponding coefficients are equal, \(a_i=b_i\) for all \(i \geq 0\).</p>

<theorem xml:id="theorem-power-series-units"><title>Units of \(F[[x]]\)</title>
<statement><p>Let \([F; +, \cdot ]\) be a field. Then \(f(x)=\sum_{i=0}^{\infty } a_i x^i\) is a unit of \(F[[x]]\)  if and only if \(a_0\neq
0\).</p></statement>
<proof>
<case direction="forward">
<p>If \(f(x)\) is a unit of \(F[[x]]\), then there exists  \(g(x)=\sum_{i=0}^{\infty } b_i x^i\) in \(F[[x]]\) such that
<me>\begin{split}
f(x)\cdot g(x) &amp;=\left(a_0 + a_1 x+a_2 x^2+ \cdots \right)\cdot \left(b_0 + b_1 x+b_2 x^2+ \cdots \right)\\
		&amp; =1\\
		&amp; = 1 + 0x + 0x^2+ \cdots\\
\end{split}
</me>.</p>
<p>Since corresponding coefficients in the equation above must be equal, \(a_0\cdot b_0=1\), which implies that \(a_0\neq 0\). </p></case>
<case direction="backward">
<p>Assume that \(a_0\neq 0\). To prove that \(f(x)\) is a unit of \(F[[x]]\) we need to find \(g(x)=\sum_{i=0}^{\infty } b_i x^i\) in
\(F[[x]]\) such that \(f(x) \cdot  g(x) =\sum_{i=0}^{\infty } d_i x^i= 1\). If we use the formula for the coefficients \(f(x) \cdot g(x)\) and equate coefficients, we get
<me>\begin{array}{ccc}
d_0= a_0\cdot  b_0= 1 &amp;\Rightarrow &amp; b_0=a_0{}^{-1} \\
d_1= a_0\cdot b_1+ a_1\cdot b_0=0&amp;\Rightarrow &amp; b_1= -a_0{}^{-1}\cdot \left(a_1\cdot b_0\right) \\
d_2=a_0 b_2+a_1 b_1+a_2 b_0=0 &amp; \Rightarrow &amp; b_2=-a_0{}^{-1}\cdot \left(a_1\cdot b_1+ a_2\cdot b_0\right)\\
\vdots  &amp; \vdots &amp; \vdots \\
\hspace{8cm}d_s= a_0\cdot b_s+ a_1\cdot b_{s-1}+ \cdots +a_s\cdot b_0 =0&amp;\\ \hspace{20cm} \Rightarrow b_s= -a_0{}^{-1}\cdot \left(a_1\cdot b_{s-1}+ a_2\cdot b_{s-2}+ \cdots +a_s\cdot b_0\right)\\
\end{array}
</me>.</p>
<p>Therefore the powers series \(\sum_{i=0}^{\infty } b_i x^i\) is an expression whose coefficients lie in \(F\) and that satisfies the statement \(f(x)
\cdot  g(x) = 1\). Hence, \(g(x)\) is the multiplicative inverse of \(f(x)\) and \(f(x)\) is a unit.</p>
</case>
</proof>
</theorem>
 
<example xml:id="ex-power-series-inversion">
<p>Let \(f(x) =1 + 2x + 3 x^2+ 4 x^3+ \cdots =\sum_{i=0}^{\infty } (i+1) x^i\)
be an element of \(\mathbb{Q}[[x]]\). Then, by <xref ref="theorem-power-series-units" text="type-global"/>, since \(a_0=1\neq 0\),  \(f(x)\) is a unit and has an inverse, call it \(g(x)\).
To compute \(g(x)\), we follow the procedure outlined in  Theorem 16.5.3 .  Using the formulas for the \(b_i'\)s, we obtain
<me>\begin{array}{c}
b_0 = 1\\
b_1= -1(2\cdot 1)=-2\\
b_2= -1(2\cdot (-2)+ 3\cdot 1) = 1\\
b_3= -1(2\cdot 1 + 3\cdot (-2)+4\cdot 1)=0\\
b_4= -1(2\cdot 0+3\cdot 1 + 4\cdot (-2)+5\cdot 1)=0\\
b_5= -1(2\cdot 0+3\cdot 0+4\cdot (1)+5\cdot (-2)+6\cdot 1)=0\\
 \vdots \\
\end{array}
</me>
For \(s \geq 3\), we have
<me>
b_s= -1(2\cdot 0 + 3\cdot 0+\cdots (s-2)\cdot 0+(s-1)\cdot 1+s\cdot (-2)+(s+1)\cdot 1)=0
</me>
Hence, \(g(x) = 1 - 2x +x^2\) is the multiplicative inverse of \(f(x)\). 
</p>
</example> 

<p>Certainly \(F[[x]]\) contains a wider variety of units than \(F[x]\). Yet \(F[[x]]\) is not a field, since \(x\in  F[[x]]\) is not a unit. So concerning the algebraic structure of \(F[[x]]\), we know that it is an integral domain that contains \(F[x]\). If we allow our power series to take on negative exponents; that is, consider expressions of the form \(f(x) =\sum_{i=-\infty }^{\infty } a_i x^i\) where all but a finite number of terms with a negative index equal zero.  These expressions are called extended power series. The set of all such expressions is a field, call it <m>E</m>. This set does contain, for example, the inverse of <m>x</m>, which is \(x^{-1}\). It can be shown that each nonzero element of <m>E</m> is a unit.</p>
</subsection>

<exercises xml:id="exercises-16-5">
<title>Exercises for Section 16.5</title>
<exercise number="1"><statement><p> Let \(f(x)=\sum_{i=0}^{\infty} a_i x^i\)  and  \(g(x)=\sum_{i=0}^{\infty } b_i x^i\) be elements of \(R[[x]]\).  Let  \(f(x) \cdot  g(x) =\sum_{i=0}^{\infty } d_i x^i= 1\).   Apply basic algebra to \(\left(a_0 + a_1 x+a_2 x^2+ \cdots \right)\cdot \left(b_0 + b_1 x+b_2 x^2+ \cdots \right)\) to derive the formula \(d_s= \sum_{i=0}^s a_i b_{s-i}\) for the coefficients of \(f(x) \cdot  g(x)\). Hence, to show that
<m>f(x) \cdot  g(x) =\sum_{s=0}^{\infty } \left(\sum_{i=0}^s a_i b_{s-i}\right) x^s</m></p>
</statement></exercise>
<exercise number="2"><statement><p><ol label="(a)">
<li><p> Prove that for any integral domain <m>D</m>, the following can be proven:
\(f(x)=\sum_{i=0}^{\infty } a_i x^i\) is a unit of \(D[[x]]\) if and only if \(a_0\) is a unit in <m>D</m>. </p></li>
<li><p>  Compare the statement in part a to that in <xref ref="theorem-power-series-units" text="type-global"/>.</p></li>
<li><p>  Give an example of the statement in part a in \(\mathbb{Z}[[x]]\).</p></li>
</ol></p>
</statement></exercise>
<exercise number="3"><statement><p> Use the formula for the product to verify that the expression \(g(x)\) of <xref ref="ex-power-series-inversion" text="type-global"/> is indeed the inverse of \(f(x)\).</p>
</statement></exercise>
<exercise number="4"><statement><p><ol label="(a)">
<li><p> Determine the inverse of \(f(x) = 1 + x + x^2 + \cdots  = \sum_{i=0}^{\infty } x^i\)in \(\mathbb{Q}[[x]]\).</p></li>
<li><p>  Repeat part a with \(f(x)\) taken in \(\mathbb{Z}_2[[x]]\).</p></li>
<li><p>  Use the method outlined in Chapter 8 to show that the power series \(f(x) = \sum_{i=0}^{\infty } x^i\) is the rational generating function
\(\frac{1}{1-x}\). What is the inverse of this function? Compare your results with those in part a.</p></li>
</ol></p>
</statement></exercise>
<exercise number="5"><statement><p><ol label="(a)">
<li><p> Determine the inverse of \(h(x) = \sum_{i=0}^{\infty } 2^i x^i\)  in \(\mathbb{Q}[[x]]\).</p></li>
<li><p> Use the procedures in Chapter 8 to find a rational generating function for \(h(x)\) in part a.  Find the multiplicative inverse of this function.</p></li>
</ol></p>
</statement><answer><p> 
<ol label="(a)">
<li><p><me>\begin{array}{c}
b_0= 1\\
b_1=(-1)(2\cdot 1) = -2\\
b_2=(-1)(2\cdot (-2)+4\cdot 1)= 0\\
b_3= (-1)(2\cdot 0 + 4\cdot (-2)+8\cdot 1)=0\\
\end{array}</me>
All other terms are zero.  Hence,  \(f(x)^{-1}= 1-2x\)</p></li>
<li><p> <me>\begin{split}
		f(x) &amp;=1+2x + 2^2x^2+ 2^3x^3+ \cdots \\
			&amp;=(2x)^0 + (2x)^1 + (2x)^2+ (2x)^3+\cdots \\
			&amp;= \frac{1}{1-2x}\\
			\end{split}</me>
The last step follows from the formula for the sum of a geometric series.</p></li></ol>
</p></answer></exercise>
<exercise number="6"><statement> <p>Let \(a(x) = 1 + 3x + 9x^2 + 27x^3 + \cdots =\sum_{i=0}^{\infty } 3^i x^i\) and
\(b(x) = 1 + x + x^2+ x^3+\cdots =\sum_{i=0}^{\infty }  x^i\) both in \(\mathbb{R}[[x]]\).
<ol label="(a)">
<li><p>  What are the first four terms (counting the constant term as the \(0^{\textrm{ th}}\) term) of \(a(x) + b(x)\)?</p></li>
<li><p>  Find a closed form expression for \(a(x)\).</p></li>
<li><p> What are the first four terms of \(a(x) b(x)\)?</p></li>
</ol></p>
</statement></exercise>
<exercise number="7"><statement><p>Write as an extended power series:
<ol label="(a)">
<li><p> \(\left(x^4-x^5\right)^{-1}\)</p></li>
<li><p>  \(\left(x^2-2x^3+x^4\right)^{-1}\)</p></li>
</ol></p>
</statement>
<answer><p>
<ol label="(a)">
<li><p><me>\begin{split}
\left(x^4-x^5\right)^{-1} &amp; =(x^4 (1-x))^{-1}\\
						&amp;=x^{-4}\frac{1}{1-x}\\
						&amp; =x^{-4}\left(\sum_{k=0}^{\infty }  x^k\right)\\
						&amp;=\sum_{k=-4}^{\infty} x^k\\
\end{split}</me>.</p></li>
<li><p> <me>\begin{split}
\left(x^4-2 x^3+x^2\right)^{-1} &amp; =\left(x^2 \left(x^2-2 x+1\right)\right)^{-1}\\
						&amp;=x^{-2}\left(1-2x+x^2\right)^{-1}\\
						&amp; =x^{-2}\left(\sum_{k=0}^{\infty } (k+1) x^k\right)\\
						&amp;=\sum_{k=-2}^{\infty} (k+2) x^k\\
\end{split}</me>.</p></li>
</ol>
</p>
</answer></exercise>
<exercise number="8"><statement><p>Derive the closed form expression \(d_i = 2^{i+1}-i -2 \) for the coefficients of the product \(f(x)\cdot g(x)\) in <xref ref="ex-ps-calculations" text="type-global"/>.</p></statement>
</exercise>
</exercises>
</section>

