<example xml:id="ex-markov_chain"><title>Markov Chains</title><p> A Markov chain is a type random process the passes in discrete time between a finite number of states.  What make the process a Markov chain is that at any time, the probabilities that the process is in a state in the next time only depends on the current state. As an example,suppose that a tennis game has reached a point where both players have won three points.   The game continues until one of the players is ahead by two points. There are five states in the process/game at this point. The terminology used in tennis for the states follows.  In any game, one of the players hits the ball first and is referred to as the server, and the other player is the receiver.  
<dl>
           <li>
             <title>Deuce</title>
             <p>
               The state in which two players are tied with at least three points each.
             </p>
           </li>
           <li>
             <title>Ad-In</title>
             <p>
               The state where the server is ahead by one point, having won a point while the game is in Deuce.
             </p>
           </li>
           <li>
             <title>Ad-Out</title>
             <p>
            The state where the receiver is ahead by one point, having won a point while the game is in Deuce.
             </p>
           </li>
           <li>
             <title>Hold</title>
             <p>
               The state where the server is ahead by two points and the game is over.  The game ends in this state.
             </p>
           </li>
           <li>
             <title>Break</title>
             <p>
               The state where the receiver is ahead by two points and the game is over.  The game ends in this state.
             </p>
           </li>
         </dl>
         
Strictly speaking, a real tennis game isn't a Markov chain because players' memories of previous points could affect their play, but the Markov chain assumption is a reasonable approximation of reality.  In what follows, we will assume that for any point, the probability that the server wins the point is 0.6.  We can visualize the process with a transition graph, where the labels on each edge indicate the probability of movement to the terminal vertex from the initial vertex of the edge.
</p>
		<figure xml:id="fig-tennis">
			 <caption>The transition graph for a tennis game that reaches Deuce.</caption>
			 <image width="90%" source="images/fig-tennis.png">
				  <description><p>A graph with five vertices, one for each possible state on a tennis game that has reached Deuce.</p></description>
			 </image>
		</figure>
<p>We might wonder as to the likelihood that the server wins a game under these assumptions if the game has reached the Deuce state.  In a later chapter, we will introduce matrix methods for doing this computation. </p>
</example>
