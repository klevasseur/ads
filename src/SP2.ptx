<?xml version="1.0" encoding="UTF-8" ?>
<!-- Generated by Pandoc using pretext.lua -->
<section xml:id="sec-binomial-processes"><title>Binomial Processes</title>
<introduction>
<p>
In this section we will concentrate of random processes that will involve one or more identical random experiments with two possible outcomes. The simplest such example would be one or more flips of a coin. Let's jump into the formal definitions and then we'll look at a few examples.</p>
</introduction>
<subsection><title>Basic Theory</title>

<definition xml:id="def-binomial-trial"><title>Binomial Trial</title>
<idx>Binomial Trial</idx>
<statement>
<p>A binomial trial is an experiment with a sample space having two elements <m>\{\textrm{success},\textrm{failure}\}</m> with probability distribution <m>Pr(\textrm{success})=p</m> and <m>Pr(\textrm{failure}))=1-p</m> for some real number <m>p</m>, <m>0 \lt p \lt 1</m>.</p>
</statement></definition>

<aside><p>Binomial trials and binomial processes are also referred to as Bernoulli trials and Bernoulli processes, after the Swiss mathematician Jacob Bernoulli (1655-1705)</p></aside>

<p>It is customary to use <m>\{\textrm{success},\textrm{failure}\}</m> as the generic sample space for a binomial trial, but in practice the sample space can be any set of cardinality two. </p>

<p>A fair coin flip is a binomial trial with <m>p=1/2</m>. If we roll a six sided die and interpret success as whether a six is rolled, this is a binomial trial with <m>p=1/6</m>. </p>

<p>A basketball player shooting a free throw, with success being whether they make the free thow, is probably not a binomial trial because the probability of success is not likely to be constant. Factors such as fatigue and game pressure are likely to change the probablity of success. However, we can think of free throw shooting as a binomial process as long as we understand that it is an approximation of reality.</p>

<p>In reality, each free throw can have some effect on the next free throw. We say that each free throw is not necessarily independent of previous ones. Independence is an important assumption when we define a binomial process. Intuitively, conditions associated with an experiment are independent if the likelihood of one does not affect the likelihood of the other. The formal definition follows and gives a precise condition.</p>

<definition xml:id="def-independence">
<idx>Independence</idx>
<statement>
<p>Two logical conditions associated with a random experiment, <m>A</m> and <m>B</m>, are independent if
<me>Pr(A \land B) = Pr(A) \cdot Pr(B)</me>
</p>
</statement></definition>


<definition xml:id="def-binomial-process"><title>Finite Binomial Process</title>
<idx>Finite Binomial Process</idx>
<idx>Binomial Process</idx>
<notation><usage>B(n,p)</usage><description></description></notation>
<statement>
<p>A finite <em>binomial process</em> is a sequence of identical independent Bernoulli trials <m>X_1</m>, <m>X_2</m>, <m>X_3</m>, <m>\dots</m>, <m>X_n</m> with probability of success <m>p</m>. We use the notation <m>B(n,p)</m> for an <m>n</m> step binomial process with probability of success <m>p</m>.
</p>
</statement></definition>

<p>The probability of any number of successes in a finite binomial process is fairly easy to derive. Instead of a general proof, we will derive one specific probability for a <m>B(6,p)</m> and the correctness of the general formula should be clear from our logic. Let's look at the probability of exactly four successes. If we were to record the outcome of six independent trials, writing S for success and F for failure, there as several ways in which we could observe four successes. One such case would be SFFSSS, and another is FSSSFS. The first these two occurred with probability <m>p\cdot (1-p)\cdot (1-p)\cdot p\cdot p\cdot p</m> while the second had probability
<m>(1-p)\cdot p\cdot p\cdot p\cdot (1-p) \cdot p</m>. But both of these products reduce to <m>p^4 \cdot (1-p)^2</m>, as do all of the other ways in which we can have four successes. The number of different orderings of four successes and two failures is <m>\binom{6}{4}</m>; think of how you have to select four positions in the sequence of six to get success. Therefore the probability of having four successes is
<me>\binom{6}{4}p^4 \cdot (1-p)^2</me>.</p>
<p>We can generalize this result to give us a formula for 
<m>k</m> successes in a <m>B(n,p)</m>.</p>

<theorem xml:id="theorem-binomial-process-probabilities"><title>Binomial Process Probabilities</title>
<idx>Binomial Process Probabilities</idx>
<statement>
<p>Given a finite <em>binomial process,</em> <m>B(n,p)</m>, the probability of exactly <m>k</m> successes, <m>0\leq k \leq n</m> is
<me>\binom{n}{k}p^k \cdot (1-p)^{n-k}</me>.
</p>
</statement></theorem>
<p>What follows isn't a proof of the theorem above, but it should make it's correctness even more convincing. We know that in a <m>B(n,p)</m> there must be anywhere from 0 to <m>n</m> successes. So let's add the probabilities we've observed. The numbers of possible successes are mutually exclusive - you can't get more than one of them to occur. So we should get a sum equal to <m>1</m>.
<me> \sum_{k=0}^n \binom{n}{k}p^k \cdot (1-p)^{n-k}= (p + (1-p))^n = 1^n=1</me>
</p>
<example xml:id="series-of-red-bets"><title>A Series of Red Bets</title>
<p>In the previous section, we've seen that a bet on Red in roulette is a binomial trial with probability of success <m>\frac{9}{19}</m>.  Suppose we plan to bet on Red nine consecutive times, each time for the same amount.  What is the probability that we win at least five times?  This is a <m>B(9,\frac{9}{19})</m> and so we can use the formula directly, adding the probabilities for five through nine wins.</p>
<sage>
	<input>
var('k')
sum(binomial(9,k)*(9./19)^k*(10/19)^(9-k),k,5,9)
	</input>
	<output>
0.43547708433322546
	</output>
</sage>
<p>If we quit after nine games, we will walk away winners around 44 percent of the time.</p> 
</example>
</subsection>
<subsection><title>A Model for Noise</title>
<example><title>The Distribution of transmission errors</title>
<p>A binary symmetric channel is an approximation of a form of noise that is often observed in a communication channel. As individual bits are transmitted, we assume that there is some fixed, usually very small, probability <m>p</m> that the value of the bit will switch, creating an error. If <m>N</m> bits are to be transmitted, this is a <m>B(N,p)</m> binomial process. </p>
<p>Suppose that 1024 bits are to be transmitted across a binary symmetric channel with <m>p=0.002</m>. For any single bit, the likelihood of an error is quite small, but we can compute the probability of having any number of errors in the full transmission. If there are to be <m>k</m> errors, then the number positions of those errors among all of the bits is <m>\binom{1024}{k}</m>. The probability of any single error pattern is <m>(0.002)^k \cdot (0.998)^{1024-k}</m>. The product
<me>\binom{1024}{k} (0.002)^k \cdot (0.998)^{1024-k}</me>
is then the probability of exactly <m>k</m> transmission errors.</p>
<p> Here is a plot of these probabilities for <m>k \leq 6</m></p>
<image source="images/fig-bsc-example.png" width="60%"/>
<p>Notice that the probability that there is no error among all bits is approximately <m>0.13</m> and it is more likely that there are 1, 2 or 3 errors in the data that is received. These error could be costly and motivates the topic of <em>coding theory</em>.</p>
</example>
</subsection>
<exercises>
<exercise><statement><p>A basketball player has made <m>85</m> percent of her free throws so far this year.  Estimate the probability that she will miss the next two free throws she attempts.  What is the probability the she makes five consecutive free throws?</p></statement>
<solution><p>She is expected to miss both free throws with probability <m>0.15^2= 0.0225</m>, or slightly more that two percent of the time. The probability that she makes five consecutive free throws is <m>0.85^5=0.4437</m>.</p></solution></exercise>

<exercise><statement><p>What is the probablity of less than two errors in transmitting eight bits on a binary symmetric channel with error probability <m>p</m>?</p></statement>
<solution component="im"><p><m>(1-p)^8 + 8 p (1-p)^7</m></p></solution></exercise>

<exercise><statement><p>How long does a sequence of random digits need to be so that the probability that a 6 had appeared is at least 2/3?</p></statement>
<hint><p>It's easier to solve a related question about the absence of a 6.</p></hint>
<solution><p>The probability that no 6 has appeared after <m>k</m> digits is <m>(\frac{9}{10})^k</m>.  If we compute these powers the smallest value of <m>k</m> for which the result is less than 1/3 is when <m>k=11</m> in which case the probability of at least one 6 is greater than 2/3.</p></solution>
</exercise>

<exercise><statement><p>A bridge hand consists of 13 randomly dealt cards from a standard deck that contains four aces.   What is the probability that a bridge player does not get dealt an ace in four consecutive hands?</p></statement>
<solution component="im"><p>If we consider being dealt a hand with no aces as a success, its probability is 
	<me>\frac{\binom{48}{13}}{\binom{52}{13}}\approx 0.3038.</me>
The probabilty of getting no aces in four consecutive hands is <m>0.3038^4 \approx 0.0085</m>.  This would be a fairly uncommon event.
</p></solution>
</exercise>

<exercise><statement><p>Teams A and B compete in a best of seven series of games.  The outcomes are independent and A has a probability of <m>\frac{3}{5}</m> of winning any single game.  What is the probability that the series lasts seven games, no matter who wins the series?</p></statement>
<solution><p>
For the series to last exactly 7 games, after the first 6 games each team must have won exactly 3 games. That way, the score is tied 3–3, forcing a 7th and final game. It doesn’t matter who wins Game 7 for this probability — we only care about the fact that we reach Game 7.</p>

<p>The probability that after 6 games the record is 3 wins for A and 3 wins for B is given by the binomial formula:

<me>
 \begin{split}
 	\Pr(\text{3–3 after 6 games}) &amp;= \binom{6}{3} (3/5)^3 (2/5)^3\\
 			&amp;= \frac{4320}{15625} \approx 0.27648\\
 	\end{split}
 	</me>

</p></solution>
</exercise>


</exercises>
</section>